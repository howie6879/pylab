{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A simple Spark app in Python\"\"\"\n",
    "import os\n",
    "import sys\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# 在创建一个新的对象前，必须调用现有对象的 stop()函数\n",
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SparkContext 是调用 Spark 功能的一个主要入口\n",
    "# SparkContext 的初始化需要 SparkConf 对象的一个实例，后者包含了 Spark 集群配 置的各种参数，比如主节点的 URL\n",
    "conf = SparkConf().setAppName(\"Spark App For Loading Json\").setMaster(\"local\")\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 弹性分布式数据集（RDD，resilient distributed dataset）是 Spark 的核心概念\n",
    "# 自己创建\n",
    "collection = [\"a\", \"b\", \"c\", \"d\"]\n",
    "rdd_from_collection = sc.parallelize(collection)\n",
    "type(rdd_from_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过输入源创建\n",
    "rdd_from_file = sc.textFile(\"file:/Users/a2017148/Documents/programming/pylab/pylab/books/Spark机器学习-第二版/datasets/UserPurchaseHistory.csv\")\n",
    "type(rdd_from_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = rdd_from_file.map(lambda line: line.split(\",\")).\\\n",
    "    map(lambda record: (record[0], record[1], record[2]))\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numPurchases = data.count()\n",
    "numPurchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('John', 'iPhone Cover', '9.99'),\n",
       " ('John', 'Headphones', '5.49'),\n",
       " ('Jack', 'iPhone Cover', '9.99'),\n",
       " ('Jill', 'Samsung Galaxy Cover', '8.95'),\n",
       " ('Bob', 'iPad Cover', '5.49')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 去重\n",
    "unique_users = data.map(lambda record: record[0]).distinct()\n",
    "type(unique_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, ['John', 'Jack', 'Jill', 'Bob'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_users.count(), unique_users.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('iPhone Cover', 2.0),\n",
       " ('Headphones', 1.0),\n",
       " ('Samsung Galaxy Cover', 1.0),\n",
       " ('iPad Cover', 1.0)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = data.map(lambda record: (record[1], 1.0)).reduceByKey(lambda a, b: a + b).collect()\n",
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('iPhone Cover', 2.0),\n",
       " ('Headphones', 1.0),\n",
       " ('Samsung Galaxy Cover', 1.0),\n",
       " ('iPad Cover', 1.0)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(products, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DataFrame[value: string], pyspark.sql.dataframe.DataFrame)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data = spark.read.text('/Users/a2017148/Documents/programming/pylab/pylab/books/Spark机器学习-第二版/datasets/UserPurchaseHistory.csv').cache()\n",
    "log_data, type(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop the SparkContext\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
